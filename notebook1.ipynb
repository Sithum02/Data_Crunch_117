{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Feature and target selection\n",
    "features = ['Month', 'Day', 'kingdom']\n",
    "targets = ['Avg_Temperature', 'Radiation', 'Wind_Speed', 'Wind_Direction', 'Rain_Amount']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "categorical_features = ['kingdom']\n",
    "numerical_features = ['Month', 'Day']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Custom MAE scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Initialize scaler for Rain_Amount\n",
    "rain_scaler = StandardScaler()\n",
    "\n",
    "def train_and_save_model(target, X, y, model_name='XGBoost'):\n",
    "    model = XGBRegressor(n_estimators=200, objective='reg:squarederror', random_state=42)\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring=mae_scorer)\n",
    "    print(f\"{target}: MAE = {-np.mean(scores)}\")\n",
    "    \n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, f'best_model_{target}.pkl')\n",
    "    return pipeline\n",
    "\n",
    "# Train first 4 models\n",
    "best_models = {}\n",
    "for target in targets[:-1]:  # Exclude Rain_Amount initially\n",
    "    X_target = data[features]\n",
    "    y_target = data[target]\n",
    "    best_models[target] = train_and_save_model(target, X_target, y_target)\n",
    "\n",
    "# Generate predictions for first 4 targets\n",
    "data_predictions = data[features].copy()\n",
    "for target in targets[:-1]:\n",
    "    model = best_models[target]\n",
    "    data_predictions[target] = model.predict(data[features])\n",
    "\n",
    "# Train Rain_Amount model with scaled target\n",
    "y_rain = data['Rain_Amount'].values.reshape(-1, 1)\n",
    "y_rain_scaled = rain_scaler.fit_transform(y_rain)  # Scale rain amount\n",
    "joblib.dump(rain_scaler, 'rain_scaler.pkl')\n",
    "\n",
    "X_rain = data_predictions  # Now includes predictions of other targets\n",
    "best_models['Rain_Amount'] = train_and_save_model('Rain_Amount', X_rain, y_rain_scaled)\n",
    "\n",
    "print(\"Model training complete. All best models saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load trained models and scaler\n",
    "best_models = {}\n",
    "for target in ['Avg_Temperature', 'Radiation', 'Wind_Speed', 'Wind_Direction', 'Rain_Amount']:\n",
    "    best_models[target] = joblib.load(f'best_model_{target}.pkl')\n",
    "\n",
    "rain_scaler = joblib.load('rain_scaler.pkl')\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Feature selection\n",
    "features = ['Month', 'Day', 'kingdom']\n",
    "\n",
    "# Step 1: Predict first 4 targets\n",
    "predictions = {}\n",
    "for target in ['Avg_Temperature', 'Radiation', 'Wind_Speed', 'Wind_Direction']:\n",
    "    print(f\"Making predictions for {target}...\")\n",
    "    model = best_models[target]\n",
    "    X_test = test_data[features]\n",
    "    predictions[target] = model.predict(X_test)\n",
    "\n",
    "# Add predictions as features for Rain_Amount prediction\n",
    "for target in ['Avg_Temperature', 'Radiation', 'Wind_Speed', 'Wind_Direction']:\n",
    "    test_data[f'Predicted_{target}'] = predictions[target]\n",
    "\n",
    "# Step 2: Predict Rain_Amount\n",
    "rain_features = features + ['Predicted_Avg_Temperature', 'Predicted_Radiation', \n",
    "                            'Predicted_Wind_Speed', 'Predicted_Wind_Direction']\n",
    "print(\"Making predictions for Rain_Amount...\")\n",
    "rain_model = best_models['Rain_Amount']\n",
    "predictions['Rain_Amount'] = rain_model.predict(test_data[rain_features])\n",
    "\n",
    "# Inverse transform Rain_Amount and clip negatives\n",
    "predictions['Rain_Amount'] = rain_scaler.inverse_transform(\n",
    "    predictions['Rain_Amount'].reshape(-1, 1)).flatten()\n",
    "predictions['Rain_Amount'] = np.maximum(predictions['Rain_Amount'], 0)\n",
    "\n",
    "# Convert predictions to DataFrame and save\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df[\"ID\"] = test_data[\"ID\"]\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions complete. Results saved to 'predictions.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
